{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages (0.7.2)\n",
      "Requirement already satisfied: langdetect in /Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages (1.0.7)\n",
      "Requirement already satisfied: six in /Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: demoji in /Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker\n",
    "!pip install langdetect\n",
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/janice/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/janice/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/janice/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from spellchecker import SpellChecker\n",
    "from langdetect import detect\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import demoji\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google = pd.read_csv(\"../data/ChatGPT-play-reviews.csv\", \n",
    "                 parse_dates=[\"at\", \"repliedAt\"])\n",
    "\n",
    "df_apple = pd.read_csv(\"../data/all_apple_reviews_janice.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "df_apple[\"content\"] = df_apple[\"title\"] + \". \" + df_apple[\"review\"]\n",
    "df_apple[\"Source\"] = \"Apple\"\n",
    "\n",
    "df_google = df_google.drop('reviewCreatedVersion', axis=1)\n",
    "df_google[\"Source\"] = \"Google\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'date', 'review', 'rating', 'isEdited', 'userName',\n",
      "       'title', 'country', 'content', 'Source'],\n",
      "      dtype='object') (8620, 10)\n",
      "Index(['reviewId', 'userName', 'content', 'score', 'thumbsUpCount', 'at',\n",
      "       'replyContent', 'repliedAt', 'appVersion', 'Source'],\n",
      "      dtype='object') (30956, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_apple.columns, df_apple.shape)\n",
    "print(df_google.columns, df_google.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple = df_apple.drop(\n",
    "    columns=['Unnamed: 0', 'isEdited', 'country', 'title', 'review']).rename(\n",
    "    {'date': 'at', 'review': 'content', 'rating': 'score'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_apple, df_google], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var for review received response\n",
    "df[\"reply\"] = np.where(df.replyContent.isnull(), 0, 1)\n",
    "df['score'] = df['score'].astype(int)\n",
    "df['Reviews'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new date features from at\n",
    "df['at_ymd'] = df['at'].dt.strftime('%D')\n",
    "# Create new column for year-quarter\n",
    "df['at_q'] = df['at'].dt.quarter\n",
    "# Create new column for year-month\n",
    "df['at_ym'] = df['at'].dt.strftime('%Y-%m')\n",
    "# Create new column for month\n",
    "df['at_m'] = df['at'].dt.strftime('%B')\n",
    "# Create new column for year-month\n",
    "df['at_wd'] = df['at'].dt.strftime('%A')\n",
    "df['at_w'] = df['at'].dt.isocalendar().week\n",
    "df['at'] = df['at'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at                   0\n",
       "score                0\n",
       "userName             1\n",
       "content              0\n",
       "Source               0\n",
       "reviewId          8620\n",
       "thumbsUpCount     8620\n",
       "replyContent     39144\n",
       "repliedAt        39144\n",
       "appVersion       13534\n",
       "reply                0\n",
       "Reviews              0\n",
       "at_ymd               0\n",
       "at_q                 0\n",
       "at_ym                0\n",
       "at_m                 0\n",
       "at_wd                0\n",
       "at_w                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display number of missing values per column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Costumer Reviews: \n",
    "Remove URLs, emails, phone numbers & punctuations.\n",
    "Remove tags, emojis, symbols & pictographs.\n",
    "Remove stop words.\n",
    "Convert to lowercase and lemmatization.\n",
    "Duplicates removal.\n",
    "Spell checking.\n",
    "Non-English reviews removal.\n",
    "Remove stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score_cat\"] = np.where(df.score == 5, \"positive\", np.where(df.score == 4, \"neutral\", \"negative\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove emojis and symbols, standardize mentions of ChatGPT and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "\n",
    "    # remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "         u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols And Pictographs\n",
    "         u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "         u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "                       \"]+\", re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    dem = demoji.findall(text)\n",
    "    for item in dem.keys():\n",
    "        text = text.replace(item, '')\n",
    "    \n",
    "    # remove all characters that are not alphanumeric\n",
    "    #text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # remove symbols\n",
    "    symbol_pattern = re.compile(r'[@#$%^&*()_+{}\\[\\]\"\\<>,/\\\\|`~]+')\n",
    "    text = symbol_pattern.sub(r'', text)\n",
    "\n",
    "    # remove - \n",
    "    dash_pattern = re.compile(r'-+')\n",
    "    text = dash_pattern.sub(r'', text)\n",
    "\n",
    "    #split the string into separate tokens\n",
    "    tokens = re.split(r\"\\s+\",text)\n",
    "\n",
    "    # normalise all words into lowercase\n",
    "    text = \" \".join([t.lower() for t in tokens])\n",
    "\n",
    "    # standardize\n",
    "    text = text.replace(\"chat gpt\", \"chatgpt\")\n",
    "    text = text.replace(\"open ai\", \"openai\")\n",
    "\n",
    "    # return final list of tokens\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30866         yo tengo\n",
       "30867    thank chatgpt\n",
       "30868       1st review\n",
       "30869         just wow\n",
       "30870     ÿ™ÿ∑ÿ®ŸäŸÇ ÿßÿ≠ÿ™ÿ±ÿßŸÅ\n",
       "             ...      \n",
       "30951             Ô∏èÔ∏èÔ∏èÔ∏è\n",
       "30952             Ô∏èÔ∏èÔ∏èÔ∏è\n",
       "30953             Ô∏èÔ∏èÔ∏èÔ∏è\n",
       "30954                Ô∏è\n",
       "30955                5\n",
       "Name: content, Length: 90, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].tail(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_text = \"Amaznig and extremely handy app for many uses.... ü§ç it's like an extension of one's fingers ‚≠êÔ∏è‚≠êÔ∏è. #ChatGPT Chat GPT OpenAI Open AI HTML Google\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrected_text = pre_process(test_text)\n",
    "#print(test_text)\n",
    "#print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_hashtags(text): \n",
    "#     hashtag_pattern = re.compile(r'#\\S+')\n",
    "#     return hashtag_pattern.sub('', text)\n",
    "# df['content'] = df['content'].apply(remove_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_duplicates = df.duplicated().sum()\n",
    "count_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at                   0\n",
       "score                0\n",
       "userName             1\n",
       "content              0\n",
       "Source               0\n",
       "reviewId          8620\n",
       "thumbsUpCount     8620\n",
       "replyContent     39144\n",
       "repliedAt        39144\n",
       "appVersion       13534\n",
       "reply                0\n",
       "Reviews              0\n",
       "at_ymd               0\n",
       "at_q                 0\n",
       "at_ym                0\n",
       "at_m                 0\n",
       "at_wd                0\n",
       "at_w                 0\n",
       "score_cat            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(comment):\n",
    "    try:\n",
    "        return detect(comment)\n",
    "    except:\n",
    "        return 'unknown' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detected_language'] = df['content'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'af', 'fr', 'no', 'nl', 'da', 'cy', 'it', 'et', 'tl', 'ro',\n",
       "       'sv', 'ca', 'hr', 'sw', 'sl', 'so', 'hu', 'pl', 'cs', 'de',\n",
       "       'unknown', 'id', 'sk', 'fi', 'zh-cn', 'pt', 'es', 'lt', 'ru', 'lv',\n",
       "       'vi', 'sq', 'ar', 'tr', 'ja', 'ko', 'ur', 'uk', 'fa', 'ml', 'ta',\n",
       "       'hi', 'bn', 'ne', 'el', 'te', 'gu', 'mr', 'th', 'kn', 'he', 'bg',\n",
       "       'mk'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['detected_language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27922 entries, 0 to 30923\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   at                 27922 non-null  object        \n",
      " 1   score              27922 non-null  int64         \n",
      " 2   userName           27921 non-null  object        \n",
      " 3   content            27922 non-null  object        \n",
      " 4   Source             27922 non-null  object        \n",
      " 5   reviewId           21344 non-null  object        \n",
      " 6   thumbsUpCount      21344 non-null  float64       \n",
      " 7   replyContent       388 non-null    object        \n",
      " 8   repliedAt          388 non-null    datetime64[ns]\n",
      " 9   appVersion         18092 non-null  object        \n",
      " 10  reply              27922 non-null  int64         \n",
      " 11  Reviews            27922 non-null  int64         \n",
      " 12  at_ymd             27922 non-null  object        \n",
      " 13  at_q               27922 non-null  int32         \n",
      " 14  at_ym              27922 non-null  object        \n",
      " 15  at_m               27922 non-null  object        \n",
      " 16  at_wd              27922 non-null  object        \n",
      " 17  at_w               27922 non-null  UInt32        \n",
      " 18  score_cat          27922 non-null  object        \n",
      " 19  detected_language  27922 non-null  object        \n",
      "dtypes: UInt32(1), datetime64[ns](1), float64(1), int32(1), int64(3), object(13)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "lang = df[df['detected_language'] == \"en\"]\n",
    "lang.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../data/chatgpt_short_clean_all_languages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into short (review-wise) and long format (sentence-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                                            content  score  \\\n",
      "75         5                absolute game changer‚Ä¶ astounding!.      5   \n",
      "76         5  once you understand how to input and work with...      5   \n",
      "77         5     i find myself using it more than i use google.      5   \n",
      "78         5  it has given me back hours an hour of time tha...      5   \n",
      "79         5  i can‚Äôt even share an effective analogy‚Ä¶ maybe...      5   \n",
      "80         5                      the difference is staggering.      5   \n",
      "81         5  the only thing i would say is you don‚Äôt use ch...      5   \n",
      "82         5              the thinking is completely different.      5   \n",
      "83         5  it is a literal conversation that continues wh...      5   \n",
      "84         5  you start carving away and refining and refini...      5   \n",
      "85         5  i‚Äôm at the point where i can do this in a litt...      5   \n",
      "86         5  when i‚Äôm working with chatgpt it feels like i‚Äô...      5   \n",
      "28588      5                                 seems to work now.      3   \n",
      "28589      5                 app seems nice but has two issues.      3   \n",
      "28590      5  the website mentions that users can enable voi...      3   \n",
      "28591      5  also when using voice dictation to compose a p...      3   \n",
      "\n",
      "      score_cat detected_language  \n",
      "75     positive                en  \n",
      "76     positive                en  \n",
      "77     positive                en  \n",
      "78     positive                en  \n",
      "79     positive                en  \n",
      "80     positive                en  \n",
      "81     positive                en  \n",
      "82     positive                en  \n",
      "83     positive                en  \n",
      "84     positive                en  \n",
      "85     positive                en  \n",
      "86     positive                en  \n",
      "28588  negative                en  \n",
      "28589  negative                en  \n",
      "28590  negative                en  \n",
      "28591  negative                en  \n"
     ]
    }
   ],
   "source": [
    "# Function to split text into sentences\n",
    "def split_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "# Split sentences and create a new DataFrame in long format\n",
    "new_rows = []\n",
    "for index, row in df.iterrows():\n",
    "    sentences = split_sentences(row['content'])\n",
    "    score = row['score']\n",
    "    score_cat = row['score_cat']\n",
    "    detected_language = row['detected_language']\n",
    "    for sentence in sentences:\n",
    "        new_rows.append({'index': index, 'content': sentence, 'score': score, 'score_cat': score_cat, 'detected_language': detected_language})\n",
    "\n",
    "df_long = pd.DataFrame(new_rows)\n",
    "\n",
    "# Print the resulting DataFrame in long format\n",
    "print(df_long[df_long['index'] == 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df['detected_language'] == \"en\"]\n",
    "df_long_en = df_long[df_long['detected_language'] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "exceptions = [\"chatgpt\", \"openai\", \"gpt\", \"html\", \"css\", \"javascript\", \"microsoft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(text): \n",
    "    words = text.split()\n",
    "    corrected_text = []\n",
    "    for word in words:\n",
    "        if word in exceptions:\n",
    "            corrected_text.append(word)\n",
    "        else: \n",
    "            corrected_word = spell.correction(word)\n",
    "            if corrected_word is not None: \n",
    "                corrected_text.append(corrected_word)\n",
    "            else:\n",
    "                corrected_text.append(word)\n",
    "    corrected_text = \" \".join(corrected_text)\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected_text2 = correct_spelling(corrected_text)\n",
    "# print(test_text)\n",
    "# print(corrected_text)\n",
    "# print(corrected_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/wpx53sjn0nv5cmny0jckrfjr0000gn/T/ipykernel_29479/367844575.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['content'] = df_en['content'].apply(correct_spelling)\n",
      "/var/folders/vl/wpx53sjn0nv5cmny0jckrfjr0000gn/T/ipykernel_29479/367844575.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_long_en['content'] = df_long_en['content'].apply(correct_spelling)\n"
     ]
    }
   ],
   "source": [
    "df_en['content'] = df_en['content'].apply(correct_spelling)\n",
    "df_long_en['content'] = df_long_en['content'].apply(correct_spelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en.to_csv(\"../data/chatgpt_short_clean_combined_en.csv\")\n",
    "df_long_en.to_csv(\"../data/chatgpt_long_clean_combined_en.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
