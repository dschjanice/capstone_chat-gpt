{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is about feature engineering with sentiment analysis and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load useful libraries and df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/janice/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/janice/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df\n",
    "df = pd.read_csv(\n",
    "    \"../data/chatgpt_after_datacleaning.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "df_long = pd.read_csv(\n",
    "    \"../data/chatgpt-long_after_datacleaning.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# var for review received response\n",
    "df[\"score_cat\"] = np.where(df.score == 5, \"positive\", np.where(df.score == 4, \"neutral\", \"negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>at_ymd</th>\n",
       "      <th>at_q</th>\n",
       "      <th>at_ym</th>\n",
       "      <th>at_m</th>\n",
       "      <th>at_wd</th>\n",
       "      <th>score_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>4000</td>\n",
       "      <td>9ae46fa4-4e9e-4a75-8810-4322f99abb04</td>\n",
       "      <td>Sammy Altaay</td>\n",
       "      <td>Its limited to 2021 information And the disappointing thing is that a lot of five-star reviews are bots not real this is very disappointing for a big app like that to have that much fake in it</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-26 20:14:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0.0022</td>\n",
       "      <td>07/26/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24028</th>\n",
       "      <td>24028</td>\n",
       "      <td>7456133c-b648-4124-9585-f142444725e5</td>\n",
       "      <td>Tabarak Ahmed</td>\n",
       "      <td>great</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-29 17:32:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2023.242</td>\n",
       "      <td>09/29/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>September</td>\n",
       "      <td>Friday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23180</th>\n",
       "      <td>23180</td>\n",
       "      <td>2289a714-c1c3-4590-9ac4-fd082cec6a2a</td>\n",
       "      <td>Buceo en San Andrés islas</td>\n",
       "      <td>excellent</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-30 23:30:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2023.256</td>\n",
       "      <td>09/30/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>September</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17296</th>\n",
       "      <td>17296</td>\n",
       "      <td>49ecba32-d847-4d23-be14-714d311c0907</td>\n",
       "      <td>Bradley</td>\n",
       "      <td>This app is god like</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-07 23:35:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2023.242</td>\n",
       "      <td>09/07/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>September</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>dc55b2e0-d04e-4382-a144-cb5d9f6820ba</td>\n",
       "      <td>shantel mcguire</td>\n",
       "      <td>Bruh.. this app this badass has light helped me so much explains what I'm trying to say but professionally and correctly with punctuation and all For example how get would fix this ratings Here's a sample review for the catgut app \"⭐⭐⭐⭐⭐ I've been using the catgut app for a while now and I'm genuinely impressed It's incredibly intuitive responsive and offers thoughtful answers to a wide range of questions The user experience is smooth and the quality of information i</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-03 00:59:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0.0039</td>\n",
       "      <td>09/03/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>September</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>739</td>\n",
       "      <td>c6831239-77eb-4abe-a58b-e2921655bef0</td>\n",
       "      <td>Shailesh Subedi</td>\n",
       "      <td>The app is very well made boasting a clean and minimalist sioux that feels smooth during used Speaking of aids responses they're not the best nor the worst</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-01 05:07:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0.0023</td>\n",
       "      <td>08/01/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>August</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27530</th>\n",
       "      <td>27530</td>\n",
       "      <td>706c8c9e-fab2-4723-b92d-0ef2516c02a9</td>\n",
       "      <td>doncandraa</td>\n",
       "      <td>dangerous</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-30 05:53:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0.0023</td>\n",
       "      <td>07/30/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>July</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21913</th>\n",
       "      <td>21913</td>\n",
       "      <td>e2b340cc-4164-42b8-b257-3b56ac2cff00</td>\n",
       "      <td>Divyakant Rai</td>\n",
       "      <td>excellent</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-06 08:49:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2023.263</td>\n",
       "      <td>10/06/23</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>October</td>\n",
       "      <td>Friday</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13141</th>\n",
       "      <td>13141</td>\n",
       "      <td>13602494-4f45-4117-9557-502089133130</td>\n",
       "      <td>Vernon Kemp</td>\n",
       "      <td>Really enjoying the app</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-09-01 21:50:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0.0039</td>\n",
       "      <td>09/01/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>September</td>\n",
       "      <td>Friday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>6499</td>\n",
       "      <td>b794b3d3-0cbd-45d9-b2ef-d43fc231dd8c</td>\n",
       "      <td>Harrys Marjan</td>\n",
       "      <td>we need more details about restricted subjects to use good thing</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-26 08:30:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0.0035</td>\n",
       "      <td>08/26/23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>August</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                              reviewId  \\\n",
       "4000         4000  9ae46fa4-4e9e-4a75-8810-4322f99abb04   \n",
       "24028       24028  7456133c-b648-4124-9585-f142444725e5   \n",
       "23180       23180  2289a714-c1c3-4590-9ac4-fd082cec6a2a   \n",
       "17296       17296  49ecba32-d847-4d23-be14-714d311c0907   \n",
       "737           737  dc55b2e0-d04e-4382-a144-cb5d9f6820ba   \n",
       "739           739  c6831239-77eb-4abe-a58b-e2921655bef0   \n",
       "27530       27530  706c8c9e-fab2-4723-b92d-0ef2516c02a9   \n",
       "21913       21913  e2b340cc-4164-42b8-b257-3b56ac2cff00   \n",
       "13141       13141  13602494-4f45-4117-9557-502089133130   \n",
       "6499         6499  b794b3d3-0cbd-45d9-b2ef-d43fc231dd8c   \n",
       "\n",
       "                        userName  \\\n",
       "4000                Sammy Altaay   \n",
       "24028              Tabarak Ahmed   \n",
       "23180  Buceo en San Andrés islas   \n",
       "17296                    Bradley   \n",
       "737              shantel mcguire   \n",
       "739              Shailesh Subedi   \n",
       "27530                 doncandraa   \n",
       "21913              Divyakant Rai   \n",
       "13141                Vernon Kemp   \n",
       "6499               Harrys Marjan   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       content  \\\n",
       "4000                                                                                                                                                                                                                                                                                          Its limited to 2021 information And the disappointing thing is that a lot of five-star reviews are bots not real this is very disappointing for a big app like that to have that much fake in it   \n",
       "24028                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    great   \n",
       "23180                                                                                                                                                                                                                                                                                                                                                                                                                                                                                excellent   \n",
       "17296                                                                                                                                                                                                                                                                                                                                                                                                                                                                     This app is god like   \n",
       "737    Bruh.. this app this badass has light helped me so much explains what I'm trying to say but professionally and correctly with punctuation and all For example how get would fix this ratings Here's a sample review for the catgut app \"⭐⭐⭐⭐⭐ I've been using the catgut app for a while now and I'm genuinely impressed It's incredibly intuitive responsive and offers thoughtful answers to a wide range of questions The user experience is smooth and the quality of information i   \n",
       "739                                                                                                                                                                                                                                                                                                                                The app is very well made boasting a clean and minimalist sioux that feels smooth during used Speaking of aids responses they're not the best nor the worst   \n",
       "27530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                dangerous   \n",
       "21913                                                                                                                                                                                                                                                                                                                                                                                                                                                                                excellent   \n",
       "13141                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Really enjoying the app   \n",
       "6499                                                                                                                                                                                                                                                                                                                                                                                                                          we need more details about restricted subjects to use good thing   \n",
       "\n",
       "       score  thumbsUpCount                   at replyContent repliedAt  \\\n",
       "4000       2              0  2023-07-26 20:14:44          NaN       NaN   \n",
       "24028      5              0  2023-09-29 17:32:28          NaN       NaN   \n",
       "23180      5              0  2023-09-30 23:30:08          NaN       NaN   \n",
       "17296      5              0  2023-09-07 23:35:01          NaN       NaN   \n",
       "737        5              1  2023-09-03 00:59:20          NaN       NaN   \n",
       "739        5              1  2023-08-01 05:07:14          NaN       NaN   \n",
       "27530      5              0  2023-07-30 05:53:23          NaN       NaN   \n",
       "21913      4              0  2023-10-06 08:49:27          NaN       NaN   \n",
       "13141      5              0  2023-09-01 21:50:12          NaN       NaN   \n",
       "6499       4              0  2023-08-26 08:30:14          NaN       NaN   \n",
       "\n",
       "       appVersion    at_ymd  at_q    at_ym       at_m      at_wd score_cat  \n",
       "4000     1.0.0022  07/26/23     3  2023-07       July  Wednesday  negative  \n",
       "24028  1.2023.242  09/29/23     3  2023-09  September     Friday  positive  \n",
       "23180  1.2023.256  09/30/23     3  2023-09  September   Saturday  positive  \n",
       "17296  1.2023.242  09/07/23     3  2023-09  September   Thursday  positive  \n",
       "737      1.0.0039  09/03/23     3  2023-09  September     Sunday  positive  \n",
       "739      1.0.0023  08/01/23     3  2023-08     August    Tuesday  positive  \n",
       "27530    1.0.0023  07/30/23     3  2023-07       July     Sunday  positive  \n",
       "21913  1.2023.263  10/06/23     4  2023-10    October     Friday   neutral  \n",
       "13141    1.0.0039  09/01/23     3  2023-09  September     Friday  positive  \n",
       "6499     1.0.0035  08/26/23     3  2023-08     August   Saturday   neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at a sample of our df\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidate_labels = [\"feature evaluation\", \"praise\", \"bug report\", \"feature request\", \"performance\", \"usage\"]\n",
    "candidate_labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "hypothesis_template = \"The sentiment of this review is {}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30956 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 11169/30956 [3:09:13<5:35:13,  1.02s/it]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/3_feature_engineering.ipynb Zelle 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/3_feature_engineering.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df_long))):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/3_feature_engineering.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     text \u001b[39m=\u001b[39m df_long\u001b[39m.\u001b[39miloc[i,][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/3_feature_engineering.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     res \u001b[39m=\u001b[39m classifier(text, candidate_labels, hypothesis_template\u001b[39m=\u001b[39;49mhypothesis_template, multi_label\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/3_feature_engineering.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     labels \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/3_feature_engineering.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     scores \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m#extracting the scores associated with the labels\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:205\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to understand extra arguments \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(sequences, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1112\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1111\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1113\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1114\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1115\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1116\u001b[0m             )\n\u001b[1;32m   1117\u001b[0m         )\n\u001b[1;32m   1118\u001b[0m     )\n\u001b[1;32m   1119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1025\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1026\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1027\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1028\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:224\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    222\u001b[0m sequence \u001b[39m=\u001b[39m inputs[\u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    223\u001b[0m model_inputs \u001b[39m=\u001b[39m {k: inputs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mmodel_input_names}\n\u001b[0;32m--> 224\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n\u001b[1;32m    226\u001b[0m model_outputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    227\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcandidate_label\u001b[39m\u001b[39m\"\u001b[39m: candidate_label,\n\u001b[1;32m    228\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m: sequence,\n\u001b[1;32m    229\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    230\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moutputs,\n\u001b[1;32m    231\u001b[0m }\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1529\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1526\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing input embeddings is currently not supported for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1527\u001b[0m     )\n\u001b[0;32m-> 1529\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1530\u001b[0m     input_ids,\n\u001b[1;32m   1531\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1532\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1533\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1534\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1535\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1536\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1537\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1538\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1539\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1540\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1541\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1542\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1543\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1544\u001b[0m )\n\u001b[1;32m   1545\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]  \u001b[39m# last hidden state\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m eos_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39meq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39meos_token_id)\u001b[39m.\u001b[39mto(hidden_states\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1243\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1240\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1242\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1244\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1245\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1246\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1247\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1248\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1249\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1250\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1252\u001b[0m \u001b[39m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:859\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    852\u001b[0m         layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    853\u001b[0m             create_custom_forward(encoder_layer),\n\u001b[1;32m    854\u001b[0m             hidden_states,\n\u001b[1;32m    855\u001b[0m             attention_mask,\n\u001b[1;32m    856\u001b[0m             (head_mask[idx] \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    857\u001b[0m         )\n\u001b[1;32m    858\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m         layer_outputs \u001b[39m=\u001b[39m encoder_layer(\n\u001b[1;32m    860\u001b[0m             hidden_states,\n\u001b[1;32m    861\u001b[0m             attention_mask,\n\u001b[1;32m    862\u001b[0m             layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    863\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:346\u001b[0m, in \u001b[0;36mBartEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(hidden_states))\n\u001b[1;32m    345\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_dropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m--> 346\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc2(hidden_states)\n\u001b[1;32m    347\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    348\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#candidate_labels = list(category_map.values())\n",
    "predictedCategories = []\n",
    "ScoreNegative = []\n",
    "ScoreNeutral = []\n",
    "ScorePositive = []\n",
    "\n",
    "for i in tqdm(range(0, len(df_long))):\n",
    "    text = df_long.iloc[i,]['content']\n",
    "    res = classifier(text, candidate_labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "    labels = res['labels'] \n",
    "    scores = res['scores'] #extracting the scores associated with the labels\n",
    "    res_dict = {label : score for label,score in zip(labels, scores)}\n",
    "    sorted_dict = dict(sorted(res_dict.items(), key=lambda x:x[1],reverse = True)) #sorting the dictionary of labels in descending order based on their score\n",
    "    categories  = next(k for i, (k,v) in enumerate(sorted_dict.items()))\n",
    "\n",
    "    ScorePositive.append(sorted_dict['positive'])\n",
    "    ScoreNeutral.append(sorted_dict['neutral'])\n",
    "    ScoreNegative.append(sorted_dict['negative'])\n",
    "    predictedCategories.append(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prep = pd.DataFrame({'category': predictedCategories, \n",
    "                             'positive_score': ScorePositive, \n",
    "                             'neutral_score': ScoreNeutral, \n",
    "                             'negative_score': ScoreNegative})\n",
    "dataset = pd.merge(df_long, dataset_prep, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>score_cat</th>\n",
       "      <th>category</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT on Android is a solid app with seamless OpenAI server connectivity, ensuring smooth interactions.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>However, it falls behind its Apple counterpart in features and updates.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>0.719351</td>\n",
       "      <td>0.980443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The voice input can be prematurely triggered by pauses, unlike on Apple.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.691213</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>0.729095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Additionally, the lack of a search function for previous messages is a drawback.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.238583</td>\n",
       "      <td>0.977248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite these, it remains a commendable app, deserving a 4-5 star rating.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998948</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>201</td>\n",
       "      <td>Still a great tool.</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.470242</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>201</td>\n",
       "      <td>Needs to improve to be worth subscription money.</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.972756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>202</td>\n",
       "      <td>ChatGPT is really helpful in many cases, especially when you need some rare knowledge.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998024</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>202</td>\n",
       "      <td>I use it for cooking, for computer programming, for writing high quality text documents, and for everything else.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.933658</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>0.005446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>202</td>\n",
       "      <td>Very advanced piece of advanced technology!</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.997861</td>\n",
       "      <td>0.015716</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  \\\n",
       "0        0   \n",
       "1        0   \n",
       "2        0   \n",
       "3        0   \n",
       "4        0   \n",
       "..     ...   \n",
       "995    201   \n",
       "996    201   \n",
       "997    202   \n",
       "998    202   \n",
       "999    202   \n",
       "\n",
       "                                                                                                               content  \\\n",
       "0            ChatGPT on Android is a solid app with seamless OpenAI server connectivity, ensuring smooth interactions.   \n",
       "1                                              However, it falls behind its Apple counterpart in features and updates.   \n",
       "2                                             The voice input can be prematurely triggered by pauses, unlike on Apple.   \n",
       "3                                     Additionally, the lack of a search function for previous messages is a drawback.   \n",
       "4                                            Despite these, it remains a commendable app, deserving a 4-5 star rating.   \n",
       "..                                                                                                                 ...   \n",
       "995                                                                                                Still a great tool.   \n",
       "996                                                                   Needs to improve to be worth subscription money.   \n",
       "997                             ChatGPT is really helpful in many cases, especially when you need some rare knowledge.   \n",
       "998  I use it for cooking, for computer programming, for writing high quality text documents, and for everything else.   \n",
       "999                                                                        Very advanced piece of advanced technology!   \n",
       "\n",
       "     score score_cat  category  positive_score  neutral_score  negative_score  \n",
       "0        4   neutral  positive        0.999617       0.399917        0.000733  \n",
       "1        4   neutral  negative        0.016458       0.719351        0.980443  \n",
       "2        4   neutral  negative        0.691213       0.317877        0.729095  \n",
       "3        4   neutral  negative        0.000823       0.238583        0.977248  \n",
       "4        4   neutral  positive        0.998948       0.003366        0.001539  \n",
       "..     ...       ...       ...             ...            ...             ...  \n",
       "995      3  negative  positive        0.999366       0.470242        0.001341  \n",
       "996      3  negative  negative        0.003718       0.662778        0.972756  \n",
       "997      5  positive  positive        0.998024       0.021908        0.000630  \n",
       "998      5  positive  positive        0.933658       0.117617        0.005446  \n",
       "999      5  positive  positive        0.997861       0.015716        0.000550  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictedCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>score_cat</th>\n",
       "      <th>category</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>116</td>\n",
       "      <td>But the app lacks many of the functionality of the browser-based version.</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.025535</td>\n",
       "      <td>0.713079</td>\n",
       "      <td>0.961945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>95</td>\n",
       "      <td>And After that I have to restart app to again write message</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.084329</td>\n",
       "      <td>0.205954</td>\n",
       "      <td>0.585535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>96</td>\n",
       "      <td>I've not been able to run this app so my review is only based on the very little interaction I have had with it.</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.213217</td>\n",
       "      <td>0.761041</td>\n",
       "      <td>0.862705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>49</td>\n",
       "      <td>It's initial login/setup screen used the default BRIGHT WHITE high contrast scheme that is very painful for me</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>0.962123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>49</td>\n",
       "      <td>However, that only kicked in after I had logged in after installation.</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.295070</td>\n",
       "      <td>0.494392</td>\n",
       "      <td>0.706550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>72</td>\n",
       "      <td>I've found it extremely helpful for generating examples to illustrate new concepts, and it's often simpler to ask ChatGPT than to ask Google</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999472</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>73</td>\n",
       "      <td>I love the voice control SO much!</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999081</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>74</td>\n",
       "      <td>Very useful for learning.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.150690</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>74</td>\n",
       "      <td>There are many other uses for this app, but just asking questions about various topics is my favorite use.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.975549</td>\n",
       "      <td>0.136075</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>202</td>\n",
       "      <td>Very advanced piece of advanced technology!</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.997861</td>\n",
       "      <td>0.015716</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  \\\n",
       "605    116   \n",
       "494     95   \n",
       "495     96   \n",
       "268     49   \n",
       "267     49   \n",
       "..     ...   \n",
       "392     72   \n",
       "393     73   \n",
       "395     74   \n",
       "398     74   \n",
       "999    202   \n",
       "\n",
       "                                                                                                                                          content  \\\n",
       "605                                                                     But the app lacks many of the functionality of the browser-based version.   \n",
       "494                                                                                   And After that I have to restart app to again write message   \n",
       "495                              I've not been able to run this app so my review is only based on the very little interaction I have had with it.   \n",
       "268                                It's initial login/setup screen used the default BRIGHT WHITE high contrast scheme that is very painful for me   \n",
       "267                                                                        However, that only kicked in after I had logged in after installation.   \n",
       "..                                                                                                                                            ...   \n",
       "392  I've found it extremely helpful for generating examples to illustrate new concepts, and it's often simpler to ask ChatGPT than to ask Google   \n",
       "393                                                                                                             I love the voice control SO much!   \n",
       "395                                                                                                                     Very useful for learning.   \n",
       "398                                    There are many other uses for this app, but just asking questions about various topics is my favorite use.   \n",
       "999                                                                                                   Very advanced piece of advanced technology!   \n",
       "\n",
       "     score score_cat  category  positive_score  neutral_score  negative_score  \n",
       "605      3  negative  negative        0.025535       0.713079        0.961945  \n",
       "494      5  positive  negative        0.084329       0.205954        0.585535  \n",
       "495      1  negative  negative        0.213217       0.761041        0.862705  \n",
       "268      3  negative  negative        0.001557       0.061183        0.962123  \n",
       "267      3  negative  negative        0.295070       0.494392        0.706550  \n",
       "..     ...       ...       ...             ...            ...             ...  \n",
       "392      5  positive  positive        0.999472       0.007115        0.000325  \n",
       "393      5  positive  positive        0.999081       0.004470        0.000640  \n",
       "395      5  positive  positive        0.998812       0.150690        0.000685  \n",
       "398      5  positive  positive        0.975549       0.136075        0.001041  \n",
       "999      5  positive  positive        0.997861       0.015716        0.000550  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 700)\n",
    "dataset.sort_values('category', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>101.465672</td>\n",
       "      <td>3.567164</td>\n",
       "      <td>0.104415</td>\n",
       "      <td>0.277386</td>\n",
       "      <td>0.810981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>71.857143</td>\n",
       "      <td>3.964286</td>\n",
       "      <td>0.275094</td>\n",
       "      <td>0.572316</td>\n",
       "      <td>0.236319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>94.989011</td>\n",
       "      <td>4.563579</td>\n",
       "      <td>0.926385</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index     score  positive_score  neutral_score  negative_score\n",
       "category                                                                     \n",
       "negative  101.465672  3.567164        0.104415       0.277386        0.810981\n",
       "neutral    71.857143  3.964286        0.275094       0.572316        0.236319\n",
       "positive   94.989011  4.563579        0.926385       0.175053        0.045800"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('category').mean('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Confusion matrix using pandas crosstab\n",
    "conf_matrix = confusion_matrix(dataset.score_cat, dataset.category)\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=plt.cm.Oranges, fmt='g'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating on review level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>score_cat</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>category_negative</th>\n",
       "      <th>category_neutral</th>\n",
       "      <th>category_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT on Android is a solid app with seamless OpenAI server connectivity, ensuring smooth interactions.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>However, it falls behind its Apple counterpart in features and updates.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>0.719351</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The voice input can be prematurely triggered by pauses, unlike on Apple.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.691213</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>0.729095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Additionally, the lack of a search function for previous messages is a drawback.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.238583</td>\n",
       "      <td>0.977248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite these, it remains a commendable app, deserving a 4-5 star rating.</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.998948</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>201</td>\n",
       "      <td>Still a great tool.</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.470242</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>201</td>\n",
       "      <td>Needs to improve to be worth subscription money.</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.972756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>202</td>\n",
       "      <td>ChatGPT is really helpful in many cases, especially when you need some rare knowledge.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.998024</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>202</td>\n",
       "      <td>I use it for cooking, for computer programming, for writing high quality text documents, and for everything else.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.933658</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>202</td>\n",
       "      <td>Very advanced piece of advanced technology!</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.997861</td>\n",
       "      <td>0.015716</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  \\\n",
       "0        0   \n",
       "1        0   \n",
       "2        0   \n",
       "3        0   \n",
       "4        0   \n",
       "..     ...   \n",
       "995    201   \n",
       "996    201   \n",
       "997    202   \n",
       "998    202   \n",
       "999    202   \n",
       "\n",
       "                                                                                                               content  \\\n",
       "0            ChatGPT on Android is a solid app with seamless OpenAI server connectivity, ensuring smooth interactions.   \n",
       "1                                              However, it falls behind its Apple counterpart in features and updates.   \n",
       "2                                             The voice input can be prematurely triggered by pauses, unlike on Apple.   \n",
       "3                                     Additionally, the lack of a search function for previous messages is a drawback.   \n",
       "4                                            Despite these, it remains a commendable app, deserving a 4-5 star rating.   \n",
       "..                                                                                                                 ...   \n",
       "995                                                                                                Still a great tool.   \n",
       "996                                                                   Needs to improve to be worth subscription money.   \n",
       "997                             ChatGPT is really helpful in many cases, especially when you need some rare knowledge.   \n",
       "998  I use it for cooking, for computer programming, for writing high quality text documents, and for everything else.   \n",
       "999                                                                        Very advanced piece of advanced technology!   \n",
       "\n",
       "     score score_cat  positive_score  neutral_score  negative_score  \\\n",
       "0        4   neutral        0.999617       0.399917        0.000733   \n",
       "1        4   neutral        0.016458       0.719351        0.980443   \n",
       "2        4   neutral        0.691213       0.317877        0.729095   \n",
       "3        4   neutral        0.000823       0.238583        0.977248   \n",
       "4        4   neutral        0.998948       0.003366        0.001539   \n",
       "..     ...       ...             ...            ...             ...   \n",
       "995      3  negative        0.999366       0.470242        0.001341   \n",
       "996      3  negative        0.003718       0.662778        0.972756   \n",
       "997      5  positive        0.998024       0.021908        0.000630   \n",
       "998      5  positive        0.933658       0.117617        0.005446   \n",
       "999      5  positive        0.997861       0.015716        0.000550   \n",
       "\n",
       "     category_negative  category_neutral  category_positive  \n",
       "0                    0                 0                  1  \n",
       "1                    1                 0                  0  \n",
       "2                    1                 0                  0  \n",
       "3                    1                 0                  0  \n",
       "4                    0                 0                  1  \n",
       "..                 ...               ...                ...  \n",
       "995                  0                 0                  1  \n",
       "996                  1                 0                  0  \n",
       "997                  0                 0                  1  \n",
       "998                  0                 0                  1  \n",
       "999                  0                 0                  1  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=[\"category\"], dtype=int)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=\"Category\")\n",
    "\n",
    "df_long_agg = dataset.groupby(['index'])[\"positive_score\", \"neutral_score\", \"negative_score\"].size().reset_index(name='Customers') \n",
    "df_weekday_price = df_sales_details_raw.groupby('sale_date_wd')['price'].agg(['max', 'min', 'mean', 'median']).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.nlp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fb4e7a82a71b285d1d2fdbccfc7dcb00fac1863548a2573de3cd7a5b08c832d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
