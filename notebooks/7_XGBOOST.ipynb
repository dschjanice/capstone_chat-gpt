{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For showing the decision tree by using plot_tree the package graphviz is required.\n",
    "Download for Mac by using brew install graphviz in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3624425304.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    $ brew install graphviz\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$ brew install graphviz  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T13:18:56.512879Z",
     "start_time": "2020-03-04T13:18:55.125606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import moduls (as many as you need)\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RSEED=1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"../data/ChatGPT-play-reviews_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['score_cat', 'category', 'vader_cat', 'pipe_cat']:\n",
    "    df[var] = df[var].astype('category')\n",
    "    df[var+\"_num\"] = df[var].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "y = df['score_cat_num']\n",
    "X = df[['category_num', 'positive_score', 'neutral_score', 'negative_score', 'vader_cat_num', 'vader_neg', 'vader_neu', 'vader_pos',\n",
    "       'blob_polarity', 'blob_subjectivity', 'pipe_cat_num', 'pipe_neg']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14946,), (6406,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_num            int8\n",
       "positive_score       float64\n",
       "neutral_score        float64\n",
       "negative_score       float64\n",
       "vader_cat_num           int8\n",
       "vader_neg            float64\n",
       "vader_neu            float64\n",
       "vader_pos            float64\n",
       "blob_polarity        float64\n",
       "blob_subjectivity    float64\n",
       "pipe_cat_num            int8\n",
       "pipe_neg             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "bst = XGBClassifier(random_state=RSEED,\n",
    "                    n_jobs=-1,) #n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic'\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set \n",
    "y_test_predicted = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Recall: 0.81\n",
      "Precision: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model \n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_test_predicted, average=\"weighted\")))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_test_predicted, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74      1101\n",
      "           1       0.31      0.07      0.12       742\n",
      "           2       0.84      0.95      0.89      4563\n",
      "\n",
      "    accuracy                           0.81      6406\n",
      "   macro avg       0.63      0.58      0.58      6406\n",
      "weighted avg       0.76      0.81      0.78      6406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('category_num', 0.9210802),\n",
       " ('pipe_cat_num', 0.010637923),\n",
       " ('positive_score', 0.010535379),\n",
       " ('negative_score', 0.0104751)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the most important features from the model\n",
    "imp = list(zip(bst.feature_names_in_,bst.feature_importances_))\n",
    "imp.sort(key = lambda tuple:tuple[1],reverse= True)\n",
    "imp[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model with a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_predicted)\n",
    "sns.heatmap(cm, cmap='YlGnBu', annot=True, fmt='d', linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install graphviz to plot tree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/xgboost/plotting.py:205\u001b[0m, in \u001b[0;36mto_graphviz\u001b[0;34m(booster, fmap, num_trees, rankdir, yes_color, no_color, condition_node_params, leaf_node_params, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Source\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb Zelle 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# plot single tree\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plot_tree(bst)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/xgboost/plotting.py:286\u001b[0m, in \u001b[0;36mplot_tree\u001b[0;34m(booster, fmap, num_trees, rankdir, ax, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     _, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m g \u001b[39m=\u001b[39m to_graphviz(booster, fmap\u001b[39m=\u001b[39;49mfmap, num_trees\u001b[39m=\u001b[39;49mnum_trees, rankdir\u001b[39m=\u001b[39;49mrankdir, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    288\u001b[0m s \u001b[39m=\u001b[39m BytesIO()\n\u001b[1;32m    289\u001b[0m s\u001b[39m.\u001b[39mwrite(g\u001b[39m.\u001b[39mpipe(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/xgboost/plotting.py:207\u001b[0m, in \u001b[0;36mto_graphviz\u001b[0;34m(booster, fmap, num_trees, rankdir, yes_color, no_color, condition_node_params, leaf_node_params, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Source\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must install graphviz to plot tree\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(booster, XGBModel):\n\u001b[1;32m    209\u001b[0m     booster \u001b[39m=\u001b[39m booster\u001b[39m.\u001b[39mget_booster()\n",
      "\u001b[0;31mImportError\u001b[0m: You must install graphviz to plot tree"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot single tree\n",
    "plot_tree(bst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': None,\n",
       " 'n_jobs': -1,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': 1234,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter space for grid-search. Since we want to access the classifier step (called 'logreg') in our pipeline \n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [1, 2, 3, 4, 5],\n",
    "        'learning_rate': [0.1, 0.2, 0.5, 1, 2, 5, 10],\n",
    "        'n_estimators': [1, 10, 100, 1000]\n",
    "        }\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softprob'\n",
    "                   ) #learning_rate=0.02, silent=True, nthread=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.808 total time=   4.7s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.813 total time=   4.7s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.821 total time=   4.7s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.811 total time=   4.8s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.8s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.825 total time=   4.7s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.813 total time=   4.8s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.8s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.813 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.823 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.082 total time=   3.5s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.086 total time=   3.5s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.643 total time=   3.2s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.096 total time=   3.4s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.091 total time=   3.5s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.094 total time=   3.5s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.821 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.819 total time=   4.7s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.811 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.819 total time=   4.9s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.822 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.819 total time=   0.1s[CV 9/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.804 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=4, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.821 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.116 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.116 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.118 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.120 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.116 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.719 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.114 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.110 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.115 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.117 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.814 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.816 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.823 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.080 total time=   3.4s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.813 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.057 total time=   3.4s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.262 total time=   3.5s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.823 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.061 total time=   3.5s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.816 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.816 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.818 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.809 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.813 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.809 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.816 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.819 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.811 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.809 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.114 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.111 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.104 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.821 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.817 total time=   0.7s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.108 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.110 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.103 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.116 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.115 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.109 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.118 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.7s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.7s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.7s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.0s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.7s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.818 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.804 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.810 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.808 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.820 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.823 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.820 total time=   0.2s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.820 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.813 total time=   0.2s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.821 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.7s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.122 total time=   3.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.113 total time=   3.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.174 total time=   3.0s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.117 total time=   3.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.120 total time=   3.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.818 total time=   3.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.718 total time=   3.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.120 total time=   3.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.115 total time=   3.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.118 total time=   3.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.821 total time=   4.2s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.813 total time=   4.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.2s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.2s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.821 total time=   4.2s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.810 total time=   4.3s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.808 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.806 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.0s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.0s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.812 total time=   4.3s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.814 total time=   4.3s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.767 total time=   3.0s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.771 total time=   3.0s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.675 total time=   3.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.108 total time=   3.4s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.823 total time=   4.4s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.819 total time=   4.5s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.821 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.813 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.815 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.811 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.815 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.817 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.795 total time=   3.0s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.816 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.343 total time=   3.2s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.781 total time=   3.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.815 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.710 total time=   3.0s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.826 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=5, learning_rate=1, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.820 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.746 total time=   3.0s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=5, max_depth=3, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.109 total time=   3.4s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.810 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.810 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.801 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.814 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.808 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.0s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.805 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=2, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.822 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.807 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.822 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.730 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.712 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.705 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.719 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.719 total time=   0.7s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.722 total time=   0.7s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.719 total time=   0.8s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.720 total time=   0.9s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.718 total time=   0.7s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=4, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.720 total time=   0.7s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.817 total time=   4.0s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.821 total time=   4.0s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.821 total time=   4.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.807 total time=   4.0s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.813 total time=   4.0s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.820 total time=   4.0s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.679 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.660 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.670 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.812 total time=   4.0s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.811 total time=   4.0s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.660 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.678 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.686 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.062 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.670 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.196 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.665 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.671 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.082 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.091 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.103 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.096 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.060 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.078 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.060 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.061 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.820 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.823 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.666 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.814 total time=   0.2s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.819 total time=   4.0s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.2, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.8;, score=0.821 total time=   4.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.726 total time=   3.3s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.324 total time=   3.3s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.770 total time=   3.3s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.823 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.822 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.759 total time=   3.6s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.741 total time=   3.7s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.787 total time=   3.8s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=4, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.823 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.819 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.818 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.818 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.807 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.812 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.822 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.813 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.816 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.0s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.0s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.812 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.799 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.810 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.821 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.819 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.817 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.819 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.818 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.809 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.333 total time=   3.3s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.580 total time=   3.6s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.814 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.824 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.810 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.815 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.819 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.812 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.823 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.822 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.824 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.818 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.818 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.814 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.807 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.821 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.816 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.822 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.807 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.805 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.808 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.807 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.769 total time=   3.9s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.807 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.809 total time=   0.2s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.724 total time=   4.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.116 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.709 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.133 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.708 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.116 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.110 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.812 total time=   0.0s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.0s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.807 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.109 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.823 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.0s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.801 total time=   0.0s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.0s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.0s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.0s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.0s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.821 total time=   0.0s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=3, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.120 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.712 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.114 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.172 total time=   3.3s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.172 total time=   3.4s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.800 total time=   3.3s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.712 total time=   3.5s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.117 total time=   3.5s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.104 total time=   3.5s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.769 total time=   0.2s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.213 total time=   3.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.787 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.114 total time=   3.6s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.767 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.785 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.356 total time=   0.2s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.666 total time=   0.2s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.409 total time=   0.2s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.246 total time=   0.2s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.776 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.645 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.110 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.118 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.116 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.712 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.113 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.819 total time=   0.7s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.111 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.114 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.112 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.110 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=10, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.090 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.817 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.810 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.811 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.813 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.823 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.813 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.810 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.822 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.824 total time=   0.7s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.810 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.805 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.820 total time=   0.0s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.822 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.816 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.172 total time=   4.3s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.730 total time=   4.4s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.813 total time=   0.2s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.824 total time=   0.2s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.821 total time=   0.2s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.821 total time=   0.2s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.815 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.816 total time=   0.2s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.809 total time=   0.2s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.818 total time=   0.2s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.819 total time=   0.2s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.820 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.812 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.821 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=10, subsample=1.0;, score=0.820 total time=   0.2s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.803 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.814 total time=   0.2s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.821 total time=   0.2s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.812 total time=   0.3s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.2s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.822 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.821 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.801 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.820 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.5, max_depth=4, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.824 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.799 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.0s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.2, max_depth=1, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.814 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.820 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.812 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.799 total time=   0.0s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.810 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.818 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.807 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.785 total time=   6.4s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.789 total time=   6.2s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.822 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.819 total time=   0.2s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.783 total time=   6.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.780 total time=   6.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.811 total time=   0.2s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.778 total time=   6.2s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.803 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.813 total time=   0.2s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=5, min_child_weight=10, n_estimators=10, subsample=0.8;, score=0.815 total time=   0.2s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=5, learning_rate=2, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.823 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.805 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.712 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.114 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.712 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.0s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=10, subsample=0.6;, score=0.116 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s[CV 7/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.805 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.0s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.799 total time=   0.0s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.804 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.819 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=0.5, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.821 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.816 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.822 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.821 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.823 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.821 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.810 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.822 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.0s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.808 total time=   0.0s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.801 total time=   0.0s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.0s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.805 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=10, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.818 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.817 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.820 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.0s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=1, subsample=1.0;, score=0.823 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.810 total time=   0.0s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.0s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.0s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.810 total time=   0.0s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.802 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.0s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=1, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.0s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.774 total time=   5.3s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.773 total time=   5.2s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.813 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.808 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.810 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.819 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.804 total time=   5.2s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.790 total time=   5.3s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=1, max_depth=3, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.787 total time=   5.3s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.823 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.818 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.812 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.815 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.813 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.815 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.813 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.805 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.821 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.812 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=10, n_estimators=100, subsample=0.6;, score=0.819 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.593 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.732 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.688 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.720 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.670 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.589 total time=   0.7s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.708 total time=   0.8s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.759 total time=   0.8s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.705 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.817 total time=   4.4s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.816 total time=   4.4s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=2, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=0.718 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.813 total time=   4.3s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.705 total time=   1.0s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.812 total time=   4.4s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.820 total time=   4.4s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.819 total time=   4.4s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.724 total time=   1.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.684 total time=   0.7s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.707 total time=   1.0s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.732 total time=   1.0s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.743 total time=   1.0s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.699 total time=   0.9s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.706 total time=   0.9s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.732 total time=   1.0s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.6;, score=0.705 total time=   0.9s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.811 total time=   4.3s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.3s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.823 total time=   4.4s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.8;, score=0.812 total time=   4.4s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.820 total time=   3.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.812 total time=   3.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.820 total time=   3.5s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.814 total time=   3.5s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.800 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.820 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.821 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.809 total time=   3.6s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.825 total time=   3.7s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.815 total time=   3.7s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.814 total time=   3.7s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.822 total time=   3.6s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.5, max_depth=2, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.823 total time=   3.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.112 total time=   3.2s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.116 total time=   3.3s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.109 total time=   3.3s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.106 total time=   3.3s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.112 total time=   3.4s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.110 total time=   3.3s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.112 total time=   3.2s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.114 total time=   3.2s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.112 total time=   3.2s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=10, max_depth=1, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.112 total time=   3.3s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.780 total time=   3.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.712 total time=   3.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.806 total time=   3.2s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.734 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.712 total time=   3.0s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.813 total time=   3.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.690 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.605 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.712 total time=   3.0s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.799 total time=   3.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.712 total time=   3.0s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.725 total time=   0.7s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.767 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.699 total time=   0.8s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.692 total time=   0.8s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.780 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.736 total time=   0.7s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=2, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.724 total time=   0.8s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.712 total time=   3.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=5, max_depth=2, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.710 total time=   3.0s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.817 total time=   3.5s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.820 total time=   3.6s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.810 total time=   3.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.817 total time=   3.6s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.815 total time=   3.6s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.822 total time=   3.5s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.815 total time=   3.6s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.811 total time=   3.7s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.820 total time=   3.4s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=1.0;, score=0.820 total time=   3.6s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.172 total time=   3.4s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.114 total time=   3.5s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.119 total time=   3.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.812 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.112 total time=   3.5s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.0s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.806 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.109 total time=   3.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.808 total time=   3.5s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.805 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.115 total time=   3.5s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.175 total time=   3.5s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.116 total time=   3.5s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1, learning_rate=10, max_depth=4, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.115 total time=   3.5s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.114 total time=   3.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.100 total time=   3.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.103 total time=   3.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.685 total time=   3.2s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.107 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.115 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.114 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.119 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.712 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.116 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.114 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.104 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.116 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.0s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1.5, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=10, subsample=1.0;, score=0.172 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.799 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.818 total time=   0.0s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.818 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=5, learning_rate=0.2, max_depth=1, min_child_weight=1, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.817 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.803 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.810 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=2, max_depth=3, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.822 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.810 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.821 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.807 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=10, max_depth=5, min_child_weight=5, n_estimators=1, subsample=0.8;, score=0.821 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.102 total time=   3.2s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.104 total time=   3.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.101 total time=   3.2s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.707 total time=   3.2s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.110 total time=   3.2s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=1.0;, score=0.095 total time=   3.2s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.817 total time=   4.5s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.816 total time=   4.6s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.809 total time=   4.3s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.4s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.796 total time=   0.0s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.811 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=1, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.812 total time=   4.4s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.823 total time=   4.5s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.815 total time=   4.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.811 total time=   4.6s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.820 total time=   4.3s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=1000, subsample=0.8;, score=0.820 total time=   4.4s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.111 total time=   3.8s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.114 total time=   3.8s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.104 total time=   3.8s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.108 total time=   3.8s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.110 total time=   3.8s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.103 total time=   3.8s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.116 total time=   4.0s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.115 total time=   3.8s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.109 total time=   3.8s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=1000, subsample=0.6;, score=0.118 total time=   3.8s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.810 total time=   3.8s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.807 total time=   3.9s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.797 total time=   3.8s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.803 total time=   3.8s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.811 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.811 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.813 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.812 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.819 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.805 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.801 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.811 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.808 total time=   3.8s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.812 total time=   3.9s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.807 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.817 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.688 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.441 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.587 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.770 total time=   3.8s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.774 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.802 total time=   3.8s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.807 total time=   3.8s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.773 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=5, max_depth=4, min_child_weight=5, n_estimators=1000, subsample=0.6;, score=0.805 total time=   3.8s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.761 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.774 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.772 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.714 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1, learning_rate=2, max_depth=2, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.782 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.811 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.816 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.823 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.812 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.809 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.805 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.812 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.818 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10, subsample=0.8;, score=0.813 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.803 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.814 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.820 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.816 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.819 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.812 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=5, max_depth=4, min_child_weight=10, n_estimators=1, subsample=0.8;, score=0.822 total time=   0.0s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.818 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.814 total time=   0.6s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.811 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.822 total time=   0.6s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.817 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.810 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.814 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.814 total time=   0.7s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.113 total time=   0.4s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.172 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.118 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.712 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.119 total time=   0.4s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.115 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.822 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=0.2, max_depth=2, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.820 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.124 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.172 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.784 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.085 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=10, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.164 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.091 total time=   0.4s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.088 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.084 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.814 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.812 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.802 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.099 total time=   0.4s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.102 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.087 total time=   0.4s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.088 total time=   0.4s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.092 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.814 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=10, max_depth=1, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.099 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=10, subsample=0.6;, score=0.820 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.648 total time=   0.4s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.742 total time=   0.5s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.738 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.638 total time=   0.4s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.676 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.684 total time=   0.5s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.639 total time=   0.5s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.713 total time=   0.4s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.697 total time=   0.4s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=2, max_depth=1, min_child_weight=5, n_estimators=100, subsample=0.6;, score=0.762 total time=   0.5s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.822 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.5s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.818 total time=   0.5s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.817 total time=   0.6s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.5s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.813 total time=   0.6s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.813 total time=   0.5s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.815 total time=   0.5s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.5s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.2, max_depth=4, min_child_weight=5, n_estimators=100, subsample=1.0;, score=0.821 total time=   0.6s\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.802 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.799 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.802 total time=   0.7s\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.805 total time=   0.7s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.0s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.806 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.812 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.807 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=5, learning_rate=1, max_depth=2, min_child_weight=10, n_estimators=1, subsample=0.6;, score=0.813 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.801 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.810 total time=   0.6s\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.810 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.0s\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.803 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.814 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.787 total time=   0.6s\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.813 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=1, learning_rate=2, max_depth=2, min_child_weight=10, n_estimators=1, subsample=1.0;, score=0.815 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.809 total time=   0.6s\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.801 total time=   0.1s\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.811 total time=   0.1s\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.819 total time=   0.1s\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.809 total time=   0.1s\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.812 total time=   0.1s\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.815 total time=   0.1s\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.799 total time=   0.6s\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.800 total time=   0.6s\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=2, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=1, subsample=0.6;, score=0.817 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x17718f640&gt;,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=No...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           objective=&#x27;multi:softprob&#x27;, ...),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0.5, 1, 1.5, 2, 5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.2, 0.5, 1, 2,\n",
       "                                                          5, 10],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [1, 10, 100, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "                   random_state=1234, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x17718f640&gt;,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=No...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           objective=&#x27;multi:softprob&#x27;, ...),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0.5, 1, 1.5, 2, 5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.2, 0.5, 1, 2,\n",
       "                                                          5, 10],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [1, 10, 100, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "                   random_state=1234, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x17718f640>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=No...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           objective='multi:softprob', ...),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'learning_rate': [0.1, 0.2, 0.5, 1, 2,\n",
       "                                                          5, 10],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'n_estimators': [1, 10, 100, 1000],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1234, scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 10\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = RSEED)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, \n",
    "                                   param_distributions=params, \n",
    "                                   n_iter=100, \n",
    "                                   scoring='accuracy', # scoring='roc_auc', 'accuracy'\n",
    "                                   n_jobs=-1, cv=skf.split(X_train,y_train),\n",
    "                                   verbose=3, \n",
    "                                   random_state=RSEED)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([4.71533439, 0.45005138, 3.42675879, 0.10613773, 0.05052159,\n",
      "       0.41982312, 0.55721898, 0.45787814, 0.59625161, 0.42221601,\n",
      "       0.6373801 , 0.05187042, 0.14007621, 3.08751848, 4.24423645,\n",
      "       0.07452044, 3.1152168 , 0.48031154, 0.50326793, 0.0505934 ,\n",
      "       0.67031281, 4.00545802, 0.40373826, 0.0850189 , 0.1261673 ,\n",
      "       3.56844449, 0.11637924, 0.47927129, 0.04916589, 0.53743052,\n",
      "       0.09013081, 0.11982567, 0.12547932, 0.38561342, 0.04984088,\n",
      "       0.05170383, 3.6084635 , 0.1623503 , 0.4915328 , 0.61891928,\n",
      "       5.68278677, 0.0517226 , 0.16340294, 0.1491442 , 0.09901979,\n",
      "       0.13281024, 0.07652051, 0.05053599, 0.51432192, 0.04889665,\n",
      "       0.151156  , 0.06399827, 0.05137458, 0.08689942, 0.04896488,\n",
      "       0.05313468, 0.05381601, 0.45220535, 0.1221899 , 0.04704792,\n",
      "       0.05324326, 0.04613965, 0.41168456, 0.61723833, 4.32972507,\n",
      "       0.58711545, 0.92135463, 3.58208826, 0.05479856, 3.25329926,\n",
      "       3.07437456, 0.65986252, 3.5512408 , 3.49332182, 0.05495591,\n",
      "       3.15036099, 0.08505013, 0.05283391, 0.0515981 , 0.05495079,\n",
      "       4.41596448, 0.04973948, 3.79933422, 3.79402251, 0.54507108,\n",
      "       0.51146538, 0.42324414, 0.41645641, 0.1116365 , 0.05174527,\n",
      "       0.57523572, 0.42904928, 0.40329168, 0.08686547, 0.44802248,\n",
      "       0.53517232, 0.62819037, 0.05069199, 0.05062649, 0.04918339]), 'std_fit_time': array([0.06786336, 0.0231329 , 0.08589862, 0.0202128 , 0.00279403,\n",
      "       0.0131456 , 0.01095694, 0.0204824 , 0.03218319, 0.00833095,\n",
      "       0.0218183 , 0.00492911, 0.0053441 , 0.0294105 , 0.11938886,\n",
      "       0.03062855, 0.13043124, 0.01085739, 0.01532138, 0.00330894,\n",
      "       0.11449867, 0.04155054, 0.01047916, 0.00300998, 0.02399246,\n",
      "       0.27237941, 0.00340239, 0.020135  , 0.00641775, 0.00712988,\n",
      "       0.00285658, 0.00494729, 0.01990384, 0.00886938, 0.00423106,\n",
      "       0.01252493, 0.35718087, 0.03791621, 0.0278969 , 0.02433495,\n",
      "       0.4691553 , 0.00301257, 0.13174711, 0.01727245, 0.01942451,\n",
      "       0.05589736, 0.01322942, 0.00328989, 0.01114778, 0.00499658,\n",
      "       0.02514935, 0.01697247, 0.00357081, 0.00655891, 0.00359525,\n",
      "       0.00711822, 0.00318375, 0.01303198, 0.00716809, 0.00417173,\n",
      "       0.00361196, 0.00413021, 0.01136661, 0.00938335, 0.01654194,\n",
      "       0.098864  , 0.10312434, 0.08157798, 0.00602457, 0.05223649,\n",
      "       0.0595294 , 0.0771855 , 0.07069234, 0.05095889, 0.01140375,\n",
      "       0.03443203, 0.01134846, 0.01297023, 0.0023873 , 0.00286435,\n",
      "       0.09155468, 0.00396596, 0.0540988 , 0.04172256, 0.00798843,\n",
      "       0.05629705, 0.0217386 , 0.02925209, 0.00417779, 0.00811444,\n",
      "       0.02578559, 0.0234728 , 0.00621452, 0.00336326, 0.01288637,\n",
      "       0.01220879, 0.01813275, 0.0032329 , 0.00397767, 0.00164747]), 'mean_score_time': array([0.04437613, 0.00627   , 0.01188364, 0.00593863, 0.005545  ,\n",
      "       0.0052583 , 0.0112462 , 0.00720942, 0.00968921, 0.00539   ,\n",
      "       0.01081283, 0.00460303, 0.00666635, 0.01126561, 0.02488999,\n",
      "       0.00730665, 0.01232536, 0.00669818, 0.00948699, 0.00421913,\n",
      "       0.01550689, 0.01440768, 0.0046216 , 0.00496418, 0.00521975,\n",
      "       0.014379  , 0.00563455, 0.00781958, 0.00897584, 0.00809238,\n",
      "       0.00443799, 0.00528016, 0.00680039, 0.00510237, 0.00453341,\n",
      "       0.0040833 , 0.02209311, 0.00676281, 0.00642242, 0.01166945,\n",
      "       0.0625375 , 0.00456331, 0.00731862, 0.00713196, 0.00614848,\n",
      "       0.01196802, 0.00481791, 0.00436583, 0.00931802, 0.00461109,\n",
      "       0.0063951 , 0.00586741, 0.00439699, 0.0053859 , 0.00481679,\n",
      "       0.00438592, 0.00468664, 0.00752807, 0.00568342, 0.00463216,\n",
      "       0.00454221, 0.00431392, 0.00563021, 0.01245599, 0.03379526,\n",
      "       0.0160152 , 0.02098153, 0.01570315, 0.0044497 , 0.01302047,\n",
      "       0.01184003, 0.01232734, 0.01347334, 0.0112828 , 0.00545387,\n",
      "       0.01223195, 0.00558903, 0.00448911, 0.00409069, 0.00434747,\n",
      "       0.03477826, 0.00448182, 0.01149735, 0.01170902, 0.00906646,\n",
      "       0.00874221, 0.005462  , 0.00535975, 0.00594645, 0.00678058,\n",
      "       0.0097038 , 0.00478606, 0.0049964 , 0.00430553, 0.00495014,\n",
      "       0.01012201, 0.01226096, 0.00408542, 0.00453985, 0.0039459 ]), 'std_score_time': array([0.0035549 , 0.00100642, 0.00172499, 0.00178874, 0.00192381,\n",
      "       0.00074169, 0.00081761, 0.00099035, 0.00219365, 0.00086614,\n",
      "       0.00123391, 0.0010142 , 0.00049185, 0.00159156, 0.01088816,\n",
      "       0.00800445, 0.00286392, 0.00129714, 0.00097436, 0.00055503,\n",
      "       0.00458827, 0.00138797, 0.00048777, 0.00118344, 0.00037504,\n",
      "       0.0036211 , 0.00052941, 0.00172649, 0.01208584, 0.00054024,\n",
      "       0.00039593, 0.00059735, 0.00135073, 0.00067338, 0.00103071,\n",
      "       0.00088985, 0.01329444, 0.00124134, 0.0027786 , 0.00425819,\n",
      "       0.00491586, 0.00063426, 0.00487059, 0.00119496, 0.00286499,\n",
      "       0.01591955, 0.00073084, 0.00050334, 0.00064479, 0.00108128,\n",
      "       0.00092267, 0.00474937, 0.00059245, 0.00244624, 0.00122218,\n",
      "       0.00084696, 0.00081182, 0.00099481, 0.00083702, 0.00134631,\n",
      "       0.0009712 , 0.00098193, 0.00040598, 0.00168908, 0.00212621,\n",
      "       0.01462137, 0.00374855, 0.00711071, 0.000678  , 0.00229568,\n",
      "       0.00100438, 0.00390675, 0.00102159, 0.00109649, 0.00294345,\n",
      "       0.00157472, 0.00111235, 0.00070883, 0.00030096, 0.00029881,\n",
      "       0.00356143, 0.00086275, 0.00134812, 0.00115017, 0.00133956,\n",
      "       0.00167327, 0.00056436, 0.00162238, 0.00060891, 0.00743158,\n",
      "       0.00180556, 0.00027063, 0.0005892 , 0.00045546, 0.00082691,\n",
      "       0.00346208, 0.0012642 , 0.00037598, 0.0014486 , 0.00042234]), 'param_subsample': masked_array(data=[0.8, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.6, 0.6, 1.0,\n",
      "                   0.6, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6, 1.0, 0.8, 0.6, 0.8,\n",
      "                   0.8, 0.6, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8, 1.0, 0.6, 0.6,\n",
      "                   0.8, 1.0, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6, 0.6, 1.0, 0.6,\n",
      "                   1.0, 0.8, 0.6, 0.8, 1.0, 0.6, 0.8, 0.6, 1.0, 0.6, 1.0,\n",
      "                   1.0, 1.0, 1.0, 0.6, 0.8, 1.0, 1.0, 1.0, 0.6, 0.8, 1.0,\n",
      "                   0.6, 1.0, 0.8, 1.0, 1.0, 0.6, 1.0, 0.8, 1.0, 1.0, 1.0,\n",
      "                   0.6, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.8, 0.8, 1.0, 1.0,\n",
      "                   0.8, 0.8, 0.6, 0.6, 0.8, 0.6, 0.6, 1.0, 0.8, 0.6, 1.0,\n",
      "                   0.6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[1000, 100, 1000, 10, 1, 100, 100, 100, 100, 100, 100,\n",
      "                   1, 10, 1000, 1000, 1, 1000, 100, 100, 1, 100, 1000,\n",
      "                   100, 10, 10, 1000, 10, 100, 1, 100, 10, 10, 10, 100, 1,\n",
      "                   1, 1000, 10, 100, 100, 1000, 1, 10, 10, 10, 1, 1, 1,\n",
      "                   100, 1, 10, 1, 1, 10, 1, 1, 1, 100, 10, 1, 1, 1, 100,\n",
      "                   100, 1000, 100, 100, 1000, 1, 1000, 1000, 100, 1000,\n",
      "                   1000, 1, 1000, 10, 1, 1, 1, 1000, 1, 1000, 1000, 100,\n",
      "                   100, 100, 100, 10, 1, 100, 100, 100, 10, 100, 100, 100,\n",
      "                   1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[5, 5, 1, 5, 5, 10, 10, 10, 1, 1, 1, 5, 5, 5, 10, 1, 1,\n",
      "                   10, 1, 5, 10, 5, 1, 1, 5, 1, 10, 1, 10, 1, 5, 5, 1, 5,\n",
      "                   1, 10, 1, 1, 1, 5, 5, 1, 5, 5, 10, 10, 5, 10, 5, 1, 10,\n",
      "                   5, 5, 5, 10, 1, 1, 5, 1, 10, 5, 1, 1, 10, 1, 1, 1, 5,\n",
      "                   1, 5, 1, 5, 1, 10, 1, 5, 5, 1, 1, 5, 10, 1, 1, 5, 5, 1,\n",
      "                   5, 10, 1, 10, 5, 5, 1, 1, 5, 5, 1, 10, 10, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 4, 1, 3, 4, 3, 5, 4, 2, 1, 5, 3, 5, 3, 2, 2, 3, 3,\n",
      "                   2, 2, 4, 3, 1, 1, 4, 2, 4, 1, 1, 2, 2, 4, 5, 3, 4, 3,\n",
      "                   4, 3, 2, 2, 3, 3, 3, 5, 2, 4, 4, 1, 2, 1, 5, 5, 3, 1,\n",
      "                   3, 1, 4, 5, 4, 2, 5, 1, 2, 5, 1, 4, 5, 2, 5, 1, 2, 3,\n",
      "                   1, 4, 2, 4, 3, 1, 3, 5, 1, 2, 1, 4, 2, 2, 2, 2, 5, 4,\n",
      "                   2, 3, 1, 1, 1, 4, 4, 2, 2, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.1, 1, 5, 1, 1, 10, 0.2, 0.5, 0.5, 10, 0.2, 0.1, 0.2,\n",
      "                   10, 0.2, 0.1, 5, 1, 0.1, 2, 2, 0.2, 5, 5, 0.5, 2, 0.5,\n",
      "                   0.1, 0.1, 0.1, 0.5, 0.2, 1, 10, 0.5, 10, 10, 2, 10,\n",
      "                   0.2, 1, 0.5, 1, 0.5, 1, 0.1, 0.5, 0.2, 0.1, 10, 1, 2,\n",
      "                   5, 10, 0.1, 10, 1, 0.5, 0.5, 10, 0.5, 1, 0.5, 0.5, 0.1,\n",
      "                   2, 2, 0.5, 0.5, 10, 5, 2, 0.2, 10, 1, 10, 10, 0.2, 2,\n",
      "                   10, 0.1, 1, 10, 5, 1, 2, 1, 1, 1, 5, 0.2, 10, 10, 0.1,\n",
      "                   2, 0.2, 1, 1, 2, 0.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[1, 2, 1, 1.5, 1, 0.5, 1, 1, 1, 0.5, 1, 1, 1.5, 5, 2,\n",
      "                   1.5, 1.5, 5, 2, 1, 5, 5, 0.5, 2, 0.5, 5, 2, 2, 5, 5, 1,\n",
      "                   0.5, 2, 1.5, 1, 0.5, 2, 1.5, 1, 2, 1.5, 2, 2, 1.5, 1,\n",
      "                   1.5, 1.5, 2, 1.5, 1.5, 1, 5, 0.5, 5, 5, 1.5, 0.5, 1.5,\n",
      "                   1, 1.5, 5, 1.5, 2, 2, 0.5, 1.5, 1, 2, 2, 5, 0.5, 1,\n",
      "                   1.5, 1, 2, 2, 1.5, 5, 2, 1, 0.5, 2, 0.5, 1.5, 1, 1, 2,\n",
      "                   2, 2, 2, 1, 2, 2, 1.5, 0.5, 1.5, 1, 5, 1, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.6, 1.0, 0.8, 0.8, 0.8, 0.6, 0.8, 0.8, 0.8, 1.0, 1.0,\n",
      "                   0.8, 0.8, 1.0, 1.0, 0.6, 0.6, 0.6, 0.6, 1.0, 0.8, 1.0,\n",
      "                   1.0, 0.8, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6,\n",
      "                   0.6, 1.0, 1.0, 0.8, 0.6, 0.8, 0.6, 0.6, 0.6, 1.0, 0.6,\n",
      "                   0.8, 0.8, 0.8, 0.8, 0.6, 1.0, 1.0, 0.8, 0.6, 1.0, 0.6,\n",
      "                   0.8, 0.8, 0.6, 0.6, 1.0, 1.0, 0.6, 0.8, 0.8, 0.6, 0.6,\n",
      "                   0.6, 0.6, 0.8, 1.0, 1.0, 1.0, 0.6, 0.6, 1.0, 1.0, 0.6,\n",
      "                   0.8, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6, 0.8, 0.8,\n",
      "                   0.6, 0.8, 0.8, 1.0, 0.6, 1.0, 1.0, 1.0, 0.6, 1.0, 0.8,\n",
      "                   1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 5, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 1, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 1, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 10, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.5, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 10, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 10, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 10, 'max_depth': 2, 'learning_rate': 0.2, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 5, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 1, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 2, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 2, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 5, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 2, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 10, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 1, 'learning_rate': 0.1, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.5, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.2, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 10, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 10, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 10, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 2, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.2, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 1, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.5, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 10, 'min_child_weight': 10, 'max_depth': 2, 'learning_rate': 1, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 0.1, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 1, 'learning_rate': 0.2, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 10, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 1, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 2, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 5, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 1, 'learning_rate': 10, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 10, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 1, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.5, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.5, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 2, 'learning_rate': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.5, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 1, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 2, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 2, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 1, 'learning_rate': 10, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 5, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 2, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.2, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 10, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 10, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 10, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 10, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.2, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 2, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 10, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 1000, 'min_child_weight': 10, 'max_depth': 1, 'learning_rate': 0.1, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 10, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 5, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 1, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 2, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 2, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 1, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.2, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 10, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 10, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 1, 'learning_rate': 0.1, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 1, 'learning_rate': 2, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.2, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 1, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 2, 'learning_rate': 1, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 1, 'min_child_weight': 10, 'max_depth': 2, 'learning_rate': 2, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 1, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.5, 'gamma': 2, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.82140468, 0.81471572, 0.08160535, 0.82073579, 0.8173913 ,\n",
      "       0.11571906, 0.82140468, 0.82073579, 0.8180602 , 0.11438127,\n",
      "       0.82073579, 0.81270903, 0.82274247, 0.12173913, 0.82073579,\n",
      "       0.81137124, 0.76722408, 0.82073579, 0.81672241, 0.81270903,\n",
      "       0.71906355, 0.82140468, 0.67892977, 0.06153846, 0.82341137,\n",
      "       0.76989967, 0.82274247, 0.8180602 , 0.81270903, 0.81672241,\n",
      "       0.8180602 , 0.8187291 , 0.80735786, 0.7090301 , 0.81204013,\n",
      "       0.81605351, 0.71237458, 0.76923077, 0.11036789, 0.8187291 ,\n",
      "       0.78528428, 0.81672241, 0.82207358, 0.82073579, 0.81672241,\n",
      "       0.8180602 , 0.81137124, 0.81471572, 0.8173913 , 0.81270903,\n",
      "       0.81538462, 0.81471572, 0.81471572, 0.11571906, 0.81471572,\n",
      "       0.81471572, 0.8173913 , 0.81672241, 0.82073579, 0.81270903,\n",
      "       0.81270903, 0.81337793, 0.8173913 , 0.8180602 , 0.81672241,\n",
      "       0.59331104, 0.70501672, 0.82006689, 0.8187291 , 0.11170569,\n",
      "       0.77993311, 0.73444816, 0.82006689, 0.11371237, 0.81204013,\n",
      "       0.11438127, 0.10702341, 0.81471572, 0.8173913 , 0.81471572,\n",
      "       0.8173913 , 0.81070234, 0.11438127, 0.81003344, 0.81070234,\n",
      "       0.68762542, 0.81538462, 0.81605351, 0.82341137, 0.8180602 ,\n",
      "       0.8180602 , 0.11304348, 0.08494983, 0.81404682, 0.74180602,\n",
      "       0.82207358, 0.79866221, 0.81270903, 0.81270903, 0.81070234]), 'split1_test_score': array([0.81270903, 0.81337793, 0.08561873, 0.8180602 , 0.82006689,\n",
      "       0.11772575, 0.81404682, 0.81672241, 0.80936455, 0.11103679,\n",
      "       0.81538462, 0.8173913 , 0.82006689, 0.11304348, 0.81538462,\n",
      "       0.80802676, 0.67491639, 0.81337793, 0.8187291 , 0.81003344,\n",
      "       0.73043478, 0.8173913 , 0.65953177, 0.19598662, 0.82006689,\n",
      "       0.7264214 , 0.82207358, 0.8187291 , 0.80869565, 0.81939799,\n",
      "       0.81672241, 0.8180602 , 0.80936455, 0.11571906, 0.8173913 ,\n",
      "       0.81672241, 0.17190635, 0.78662207, 0.11438127, 0.81672241,\n",
      "       0.77391304, 0.81003344, 0.81605351, 0.81471572, 0.81471572,\n",
      "       0.8180602 , 0.82006689, 0.81270903, 0.82006689, 0.80869565,\n",
      "       0.80869565, 0.8187291 , 0.81404682, 0.11371237, 0.81404682,\n",
      "       0.81270903, 0.82006689, 0.81939799, 0.81538462, 0.81003344,\n",
      "       0.81672241, 0.81003344, 0.8173913 , 0.81270903, 0.81538462,\n",
      "       0.73244147, 0.72441472, 0.81204013, 0.81605351, 0.11571906,\n",
      "       0.71237458, 0.690301  , 0.81672241, 0.17190635, 0.80936455,\n",
      "       0.10301003, 0.11505017, 0.81270903, 0.81404682, 0.81137124,\n",
      "       0.81605351, 0.81270903, 0.11103679, 0.80668896, 0.81070234,\n",
      "       0.77391304, 0.81471572, 0.81471572, 0.81471572, 0.8180602 ,\n",
      "       0.81404682, 0.17190635, 0.0909699 , 0.81204013, 0.64816054,\n",
      "       0.81672241, 0.80200669, 0.80936455, 0.81003344, 0.81672241]), 'split2_test_score': array([0.81270903, 0.8173913 , 0.64347826, 0.81672241, 0.8187291 ,\n",
      "       0.11571906, 0.8173913 , 0.81605351, 0.81337793, 0.10434783,\n",
      "       0.81471572, 0.8180602 , 0.82006689, 0.11973244, 0.81337793,\n",
      "       0.81070234, 0.10769231, 0.81538462, 0.8173913 , 0.81137124,\n",
      "       0.70501672, 0.82140468, 0.67023411, 0.08227425, 0.81404682,\n",
      "       0.78662207, 0.81939799, 0.8180602 , 0.81204013, 0.8180602 ,\n",
      "       0.82006689, 0.8180602 , 0.81137124, 0.7083612 , 0.81404682,\n",
      "       0.81538462, 0.11705686, 0.76722408, 0.11839465, 0.81137124,\n",
      "       0.78862876, 0.81672241, 0.8187291 , 0.82073579, 0.81672241,\n",
      "       0.81939799, 0.82073579, 0.81270903, 0.81672241, 0.81204013,\n",
      "       0.8187291 , 0.81939799, 0.8173913 , 0.71237458, 0.8173913 ,\n",
      "       0.81270903, 0.8187291 , 0.81939799, 0.81538462, 0.81137124,\n",
      "       0.8180602 , 0.80869565, 0.8187291 , 0.81204013, 0.81605351,\n",
      "       0.68829431, 0.68361204, 0.82006689, 0.81672241, 0.1090301 ,\n",
      "       0.80602007, 0.60535117, 0.8173913 , 0.11906355, 0.81137124,\n",
      "       0.09966555, 0.11371237, 0.81270903, 0.81605351, 0.81337793,\n",
      "       0.81538462, 0.81471572, 0.10434783, 0.79732441, 0.81337793,\n",
      "       0.44080268, 0.8173913 , 0.8180602 , 0.8187291 , 0.81939799,\n",
      "       0.81404682, 0.71237458, 0.08829431, 0.81270903, 0.73779264,\n",
      "       0.81672241, 0.80200669, 0.81137124, 0.81404682, 0.8187291 ]), 'split3_test_score': array([0.81070234, 0.81204013, 0.0909699 , 0.81070234, 0.80401338,\n",
      "       0.12040134, 0.81605351, 0.81204013, 0.80936455, 0.1083612 ,\n",
      "       0.81204013, 0.80401338, 0.81337793, 0.11705686, 0.81003344,\n",
      "       0.80602007, 0.77056856, 0.81137124, 0.81003344, 0.8006689 ,\n",
      "       0.71906355, 0.80735786, 0.65953177, 0.0909699 , 0.81605351,\n",
      "       0.32374582, 0.81137124, 0.80668896, 0.7993311 , 0.80936455,\n",
      "       0.81070234, 0.80735786, 0.80535117, 0.13311037, 0.80668896,\n",
      "       0.80133779, 0.17190635, 0.35585284, 0.11103679, 0.81003344,\n",
      "       0.77324415, 0.80468227, 0.81137124, 0.80936455, 0.81270903,\n",
      "       0.80334448, 0.8006689 , 0.7993311 , 0.81204013, 0.7993311 ,\n",
      "       0.81070234, 0.80334448, 0.80468227, 0.11571906, 0.80468227,\n",
      "       0.7993311 , 0.80401338, 0.81204013, 0.81270903, 0.8006689 ,\n",
      "       0.80869565, 0.80200669, 0.81003344, 0.80468227, 0.81137124,\n",
      "       0.71973244, 0.70702341, 0.81404682, 0.8       , 0.11170569,\n",
      "       0.71237458, 0.72508361, 0.81003344, 0.11170569, 0.80602007,\n",
      "       0.68494983, 0.11906355, 0.7993311 , 0.80267559, 0.80936455,\n",
      "       0.80936455, 0.79598662, 0.1083612 , 0.80334448, 0.81204013,\n",
      "       0.58729097, 0.81204013, 0.81204013, 0.80936455, 0.80334448,\n",
      "       0.81137124, 0.11772575, 0.08361204, 0.80200669, 0.67558528,\n",
      "       0.81270903, 0.80535117, 0.80602007, 0.80267559, 0.80133779]), 'split4_test_score': array([0.81538462, 0.81672241, 0.09364548, 0.81404682, 0.81337793,\n",
      "       0.11571906, 0.81939799, 0.81605351, 0.81605351, 0.11036789,\n",
      "       0.8180602 , 0.81337793, 0.81538462, 0.17391304, 0.81471572,\n",
      "       0.81404682, 0.34314381, 0.81471572, 0.81404682, 0.80936455,\n",
      "       0.71906355, 0.81337793, 0.67759197, 0.10301003, 0.8173913 ,\n",
      "       0.74113712, 0.81538462, 0.81204013, 0.81003344, 0.81404682,\n",
      "       0.81204013, 0.81404682, 0.80802676, 0.11638796, 0.81070234,\n",
      "       0.81070234, 0.11438127, 0.78528428, 0.11571906, 0.81270903,\n",
      "       0.7826087 , 0.81270903, 0.81672241, 0.81605351, 0.81672241,\n",
      "       0.81404682, 0.81471572, 0.81471572, 0.81404682, 0.81003344,\n",
      "       0.81270903, 0.81538462, 0.81270903, 0.11571906, 0.81270903,\n",
      "       0.81471572, 0.81337793, 0.81605351, 0.81672241, 0.80936455,\n",
      "       0.81337793, 0.81137124, 0.81270903, 0.81471572, 0.81270903,\n",
      "       0.66956522, 0.73244147, 0.81471572, 0.80869565, 0.10635452,\n",
      "       0.81337793, 0.69899666, 0.81538462, 0.1090301 , 0.80936455,\n",
      "       0.10234114, 0.71237458, 0.81471572, 0.81003344, 0.81003344,\n",
      "       0.81204013, 0.81070234, 0.11036789, 0.81204013, 0.80535117,\n",
      "       0.77257525, 0.81538462, 0.81471572, 0.8180602 , 0.81404682,\n",
      "       0.81672241, 0.11505017, 0.09899666, 0.81070234, 0.68361204,\n",
      "       0.8180602 , 0.8006689 , 0.80936455, 0.81070234, 0.81070234]), 'split5_test_score': array([0.82474916, 0.8180602 , 0.09632107, 0.8180602 , 0.8180602 ,\n",
      "       0.71906355, 0.82341137, 0.8187291 , 0.8187291 , 0.10301003,\n",
      "       0.82140468, 0.81672241, 0.82073579, 0.8180602 , 0.82140468,\n",
      "       0.81404682, 0.79464883, 0.81672241, 0.82207358, 0.81538462,\n",
      "       0.71237458, 0.82006689, 0.68628763, 0.09632107, 0.8180602 ,\n",
      "       0.75919732, 0.81939799, 0.82207358, 0.82006689, 0.82408027,\n",
      "       0.82274247, 0.82073579, 0.81070234, 0.11036789, 0.82006689,\n",
      "       0.8173913 , 0.10367893, 0.66622074, 0.11237458, 0.82207358,\n",
      "       0.80401338, 0.81337793, 0.82408027, 0.8187291 , 0.81672241,\n",
      "       0.81538462, 0.81538462, 0.8180602 , 0.82140468, 0.8180602 ,\n",
      "       0.81471572, 0.8173913 , 0.81404682, 0.71237458, 0.81404682,\n",
      "       0.8180602 , 0.8180602 , 0.82207358, 0.81939799, 0.81538462,\n",
      "       0.82006689, 0.81003344, 0.82140468, 0.82073579, 0.82274247,\n",
      "       0.58929766, 0.74314381, 0.82541806, 0.81404682, 0.11036789,\n",
      "       0.71237458, 0.76655518, 0.82207358, 0.80802676, 0.81404682,\n",
      "       0.10367893, 0.11571906, 0.8180602 , 0.8180602 , 0.82073579,\n",
      "       0.82274247, 0.81404682, 0.10301003, 0.80802676, 0.81939799,\n",
      "       0.76120401, 0.8173913 , 0.8173913 , 0.8180602 , 0.81538462,\n",
      "       0.82207358, 0.11906355, 0.10234114, 0.8187291 , 0.63879599,\n",
      "       0.82073579, 0.81003344, 0.81204013, 0.81404682, 0.8187291 ]), 'split6_test_score': array([0.80789826, 0.81191432, 0.07965194, 0.81526104, 0.8145917 ,\n",
      "       0.11044177, 0.81258367, 0.8145917 , 0.8085676 , 0.11579652,\n",
      "       0.81191432, 0.80789826, 0.81325301, 0.71820616, 0.81191432,\n",
      "       0.80923695, 0.7811245 , 0.81593039, 0.80722892, 0.80789826,\n",
      "       0.72155288, 0.81057564, 0.67001339, 0.05957162, 0.81392236,\n",
      "       0.57965194, 0.81325301, 0.81258367, 0.8085676 , 0.80990629,\n",
      "       0.80923695, 0.81526104, 0.80923695, 0.10910308, 0.80923695,\n",
      "       0.80923695, 0.79986613, 0.40896921, 0.71218206, 0.80990629,\n",
      "       0.77777778, 0.81124498, 0.81325301, 0.81057564, 0.81191432,\n",
      "       0.81593039, 0.81325301, 0.81057564, 0.80722892, 0.8085676 ,\n",
      "       0.81057564, 0.81057564, 0.81124498, 0.11579652, 0.81124498,\n",
      "       0.81057564, 0.8145917 , 0.81659973, 0.81258367, 0.80789826,\n",
      "       0.80923695, 0.8085676 , 0.80789826, 0.81258367, 0.81191432,\n",
      "       0.708166  , 0.69879518, 0.80923695, 0.8145917 , 0.1124498 ,\n",
      "       0.79852744, 0.69210174, 0.81057564, 0.11512718, 0.8085676 ,\n",
      "       0.10107095, 0.11445783, 0.81057564, 0.80923695, 0.80655957,\n",
      "       0.81057564, 0.81124498, 0.11579652, 0.80187416, 0.80053548,\n",
      "       0.77376171, 0.81124498, 0.81191432, 0.80455154, 0.81593039,\n",
      "       0.80990629, 0.12449799, 0.08701473, 0.80923695, 0.63788487,\n",
      "       0.8145917 , 0.78714859, 0.80655957, 0.80923695, 0.8085676 ]), 'split7_test_score': array([0.81526104, 0.81860776, 0.05689424, 0.82195448, 0.81927711,\n",
      "       0.11445783, 0.82128514, 0.81860776, 0.81057564, 0.11512718,\n",
      "       0.81793842, 0.80990629, 0.81526104, 0.12048193, 0.81392236,\n",
      "       0.80923695, 0.71017403, 0.8145917 , 0.81191432, 0.81258367,\n",
      "       0.71954485, 0.81191432, 0.67135207, 0.07764391, 0.81793842,\n",
      "       0.33266399, 0.81526104, 0.81593039, 0.81325301, 0.81526104,\n",
      "       0.81526104, 0.81593039, 0.80722892, 0.12048193, 0.81793842,\n",
      "       0.81726908, 0.21285141, 0.77576975, 0.11044177, 0.81325301,\n",
      "       0.78714859, 0.81526104, 0.81860776, 0.81860776, 0.81793842,\n",
      "       0.82128514, 0.81124498, 0.81659973, 0.81191432, 0.81325301,\n",
      "       0.81927711, 0.81258367, 0.8145917 , 0.11579652, 0.8145917 ,\n",
      "       0.81659973, 0.81927711, 0.81726908, 0.81325301, 0.81258367,\n",
      "       0.81526104, 0.81325301, 0.81526104, 0.81191432, 0.81191432,\n",
      "       0.75903614, 0.73226238, 0.81392236, 0.81994645, 0.11378849,\n",
      "       0.71218206, 0.7356091 , 0.81526104, 0.1746988 , 0.81258367,\n",
      "       0.70749665, 0.10374833, 0.81659973, 0.81593039, 0.81793842,\n",
      "       0.8145917 , 0.81860776, 0.11512718, 0.77041499, 0.81124498,\n",
      "       0.78246319, 0.81793842, 0.81793842, 0.81191432, 0.81927711,\n",
      "       0.81392236, 0.78380187, 0.08835341, 0.81392236, 0.71285141,\n",
      "       0.81325301, 0.80923695, 0.81124498, 0.81258367, 0.81191432]), 'split8_test_score': array([0.81927711, 0.82329317, 0.26238286, 0.81659973, 0.81392236,\n",
      "       0.11512718, 0.82329317, 0.82128514, 0.81726908, 0.10910308,\n",
      "       0.81927711, 0.8145917 , 0.81726908, 0.11512718, 0.82262383,\n",
      "       0.81057564, 0.10910308, 0.82597055, 0.8206158 , 0.80522088,\n",
      "       0.71753681, 0.81927711, 0.66532798, 0.06024096, 0.81659973,\n",
      "       0.76907631, 0.81593039, 0.81927711, 0.81726908, 0.81927711,\n",
      "       0.81994645, 0.81726908, 0.8085676 , 0.71218206, 0.81057564,\n",
      "       0.81124498, 0.73025435, 0.24631861, 0.11311914, 0.82329317,\n",
      "       0.78045515, 0.81258367, 0.8145917 , 0.81793842, 0.82128514,\n",
      "       0.81191432, 0.81325301, 0.81726908, 0.82128514, 0.81726908,\n",
      "       0.81325301, 0.81726908, 0.8145917 , 0.11579652, 0.8145917 ,\n",
      "       0.81860776, 0.81392236, 0.82329317, 0.8206158 , 0.80522088,\n",
      "       0.81526104, 0.81392236, 0.81927711, 0.81526104, 0.81994645,\n",
      "       0.70481928, 0.70615797, 0.82195448, 0.81392236, 0.11178046,\n",
      "       0.71218206, 0.77978581, 0.81994645, 0.11646586, 0.80522088,\n",
      "       0.11044177, 0.11646586, 0.81793842, 0.81526104, 0.81057564,\n",
      "       0.81994645, 0.81526104, 0.10910308, 0.80722892, 0.80722892,\n",
      "       0.77242303, 0.8206158 , 0.8206158 , 0.81392236, 0.81191432,\n",
      "       0.82195448, 0.17202142, 0.09170013, 0.81659973, 0.76171352,\n",
      "       0.8206158 , 0.79986613, 0.81726908, 0.81258367, 0.81526104]), 'split9_test_score': array([0.81860776, 0.81659973, 0.06091031, 0.81927711, 0.8206158 ,\n",
      "       0.11713521, 0.81927711, 0.81927711, 0.82128514, 0.11780455,\n",
      "       0.81659973, 0.81994645, 0.81994645, 0.1184739 , 0.81927711,\n",
      "       0.81927711, 0.74564926, 0.81994645, 0.82195448, 0.81659973,\n",
      "       0.71954485, 0.8206158 , 0.66599732, 0.06091031, 0.81927711,\n",
      "       0.72356091, 0.82262383, 0.82128514, 0.81526104, 0.82195448,\n",
      "       0.82396252, 0.82195448, 0.80655957, 0.11378849, 0.82329317,\n",
      "       0.82128514, 0.17202142, 0.64524766, 0.09036145, 0.82396252,\n",
      "       0.79049531, 0.81994645, 0.81793842, 0.81994645, 0.81994645,\n",
      "       0.82195448, 0.82396252, 0.81659973, 0.82195448, 0.81526104,\n",
      "       0.81526104, 0.82262383, 0.81927711, 0.11579652, 0.81927711,\n",
      "       0.81659973, 0.8206158 , 0.81726908, 0.82195448, 0.81659973,\n",
      "       0.82262383, 0.81325301, 0.82329317, 0.81860776, 0.81927711,\n",
      "       0.71820616, 0.70548862, 0.82329317, 0.82128514, 0.11178046,\n",
      "       0.71017403, 0.72356091, 0.81994645, 0.11512718, 0.81526104,\n",
      "       0.09504685, 0.17202142, 0.81659973, 0.82195448, 0.8206158 ,\n",
      "       0.81994645, 0.81593039, 0.11780455, 0.80455154, 0.81726908,\n",
      "       0.71352075, 0.82128514, 0.81994645, 0.81258367, 0.82195448,\n",
      "       0.81994645, 0.16398929, 0.09906292, 0.81994645, 0.69745649,\n",
      "       0.82128514, 0.79919679, 0.81325301, 0.81526104, 0.81726908]), 'mean_test_score': array([0.8158703 , 0.81627227, 0.15514782, 0.81714201, 0.81600458,\n",
      "       0.17615098, 0.81881448, 0.81740962, 0.81426473, 0.11093363,\n",
      "       0.81680707, 0.8134617 , 0.81781042, 0.25358343, 0.81633898,\n",
      "       0.81125407, 0.58042449, 0.81687468, 0.81607102, 0.81018343,\n",
      "       0.71831961, 0.81633862, 0.67047978, 0.08884671, 0.81767677,\n",
      "       0.65119766, 0.81774362, 0.81647285, 0.8117227 , 0.81680712,\n",
      "       0.81687414, 0.8167405 , 0.8083767 , 0.29485321, 0.81419806,\n",
      "       0.81366281, 0.33062977, 0.620674  , 0.17083787, 0.81620538,\n",
      "       0.78435691, 0.81332836, 0.8173421 , 0.81674027, 0.81653987,\n",
      "       0.81593787, 0.81446567, 0.8133285 , 0.81640551, 0.81152203,\n",
      "       0.81393033, 0.81520154, 0.81372975, 0.23488048, 0.81372975,\n",
      "       0.81346237, 0.81600458, 0.81801167, 0.81687414, 0.81018343,\n",
      "       0.8152015 , 0.81045144, 0.81633884, 0.81413099, 0.81580355,\n",
      "       0.68828697, 0.71383563, 0.81747615, 0.81439931, 0.11146821,\n",
      "       0.74695204, 0.71517933, 0.81674018, 0.19548638, 0.81038406,\n",
      "       0.2222083 , 0.17896366, 0.81339543, 0.81406437, 0.81352881,\n",
      "       0.81580368, 0.81199071, 0.11093363, 0.80215278, 0.81078504,\n",
      "       0.706558  , 0.8163392 , 0.81633916, 0.8145313 , 0.81573706,\n",
      "       0.81620507, 0.25934745, 0.09152951, 0.81299396, 0.69356588,\n",
      "       0.81767691, 0.80141776, 0.81091962, 0.81138794, 0.81299351]), 'std_test_score': array([0.00489305, 0.00327428, 0.17198977, 0.00312054, 0.00468046,\n",
      "       0.18098678, 0.00354626, 0.00271421, 0.00436721, 0.00465601,\n",
      "       0.00314049, 0.00473272, 0.00317368, 0.258783  , 0.00413057,\n",
      "       0.00355942, 0.26687188, 0.0040324 , 0.00486358, 0.00450378,\n",
      "       0.00612223, 0.00485256, 0.0081195 , 0.03887176, 0.00269302,\n",
      "       0.1705229 , 0.00385767, 0.00450903, 0.00540228, 0.00454761,\n",
      "       0.00477632, 0.00386005, 0.00176244, 0.27175763, 0.00502366,\n",
      "       0.00537729, 0.27548317, 0.19493731, 0.18059225, 0.00523033,\n",
      "       0.00863187, 0.00401828, 0.00365585, 0.00384787, 0.00274973,\n",
      "       0.00514236, 0.00612393, 0.00517147, 0.00472305, 0.00511842,\n",
      "       0.0032733 , 0.00513153, 0.00368663, 0.23874782, 0.00368663,\n",
      "       0.00528776, 0.00468046, 0.00304121, 0.00338262, 0.00450378,\n",
      "       0.00420351, 0.0033978 , 0.00464679, 0.00428605, 0.00371394,\n",
      "       0.05355124, 0.01746164, 0.00509741, 0.00587645, 0.00240894,\n",
      "       0.04359648, 0.04609349, 0.00384063, 0.20551755, 0.00311187,\n",
      "       0.23711591, 0.17871925, 0.00522608, 0.00517124, 0.00463193,\n",
      "       0.00411896, 0.00584959, 0.00465601, 0.01130736, 0.00521513,\n",
      "       0.10571412, 0.00310506, 0.00285206, 0.00508646, 0.00496581,\n",
      "       0.00403447, 0.24592645, 0.00613726, 0.00487113, 0.04230653,\n",
      "       0.00325702, 0.00608801, 0.00313656, 0.00341441, 0.00519835]), 'rank_test_score': array([ 34,  27,  95,  10,  31,  93,   1,   8,  43,  97,  15,  53,   3,\n",
      "        88,  24,  63,  84,  11,  30,  68,  75,  26,  81, 100,   6,  82,\n",
      "         4,  20,  60,  14,  12,  16,  70,  86,  44,  50,  85,  83,  94,\n",
      "        28,  73,  56,   9,  17,  19,  33,  41,  55,  21,  61,  47,  38,\n",
      "        48,  89,  48,  52,  31,   2,  13,  68,  39,  66,  25,  45,  36,\n",
      "        80,  77,   7,  42,  96,  74,  76,  18,  91,  67,  90,  92,  54,\n",
      "        46,  51,  35,  59,  97,  71,  65,  78,  22,  23,  40,  37,  29,\n",
      "        87,  99,  57,  79,   5,  72,  64,  62,  58], dtype=int32)}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=1, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "\n",
      " Best normalized gini score for 10-fold search with 5 parameter combinations:\n",
      "0.6376289550621661\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 1, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best estimator (including fitted preprocessing steps) as best_model \n",
    "best_model = random_search.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Recall: 0.82\n",
      "Precision: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the optimized model\n",
    "y_test_predicted = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate your model \n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_test_predicted, average=\"weighted\")))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_test_predicted, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1101\n",
      "           1       0.39      0.03      0.06       742\n",
      "           2       0.83      0.97      0.90      4563\n",
      "\n",
      "    accuracy                           0.82      6406\n",
      "   macro avg       0.66      0.58      0.57      6406\n",
      "weighted avg       0.77      0.82      0.77      6406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install graphviz to plot tree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/xgboost/plotting.py:205\u001b[0m, in \u001b[0;36mto_graphviz\u001b[0;34m(booster, fmap, num_trees, rankdir, yes_color, no_color, condition_node_params, leaf_node_params, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Source\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb Zelle 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m30\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plot_tree(best_model, num_trees\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, ax\u001b[39m=\u001b[39;49max)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janice/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/notebooks/7_XGBOOST.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#plt.savefig(\"temp.pdf\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/xgboost/plotting.py:286\u001b[0m, in \u001b[0;36mplot_tree\u001b[0;34m(booster, fmap, num_trees, rankdir, ax, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     _, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m g \u001b[39m=\u001b[39m to_graphviz(booster, fmap\u001b[39m=\u001b[39;49mfmap, num_trees\u001b[39m=\u001b[39;49mnum_trees, rankdir\u001b[39m=\u001b[39;49mrankdir, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    288\u001b[0m s \u001b[39m=\u001b[39m BytesIO()\n\u001b[1;32m    289\u001b[0m s\u001b[39m.\u001b[39mwrite(g\u001b[39m.\u001b[39mpipe(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/Bootcamp/Git/Capstone/capstone_chat-gpt/.venv/lib/python3.11/site-packages/xgboost/plotting.py:207\u001b[0m, in \u001b[0;36mto_graphviz\u001b[0;34m(booster, fmap, num_trees, rankdir, yes_color, no_color, condition_node_params, leaf_node_params, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Source\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must install graphviz to plot tree\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(booster, XGBModel):\n\u001b[1;32m    209\u001b[0m     booster \u001b[39m=\u001b[39m booster\u001b[39m.\u001b[39mget_booster()\n",
      "\u001b[0;31mImportError\u001b[0m: You must install graphviz to plot tree"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x3000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "plot_tree(best_model, num_trees=4, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig(\"temp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
